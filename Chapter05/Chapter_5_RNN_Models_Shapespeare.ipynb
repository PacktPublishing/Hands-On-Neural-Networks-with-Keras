{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Bidirectional, Dropout\n",
    "from keras.layers import SimpleRNN, GRU, BatchNormalization\n",
    "\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', 'William', 'Shakespeare', '1599', ']']\n"
     ]
    }
   ],
   "source": [
    "hamlet = gutenberg.words('shakespeare-hamlet.txt')   # Ordered list of words in Hamlet\n",
    "\n",
    "print(hamlet[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length, Hamlet only: 166765\n"
     ]
    }
   ],
   "source": [
    "text =''\n",
    "\n",
    "for word in hamlet:            # For each word\n",
    "    text+=str(word).lower()    # Convert to lower case and add to string variable\n",
    "    text+= ' '                 # Add space\n",
    "    \n",
    "    \n",
    "print('Corpus length, Hamlet only:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Break text into :\n",
    "\n",
    "Features  -    Character-level sequences of fixed length        \n",
    "Labels    -    The next character in sequence     \n",
    "\n",
    "'''\n",
    "\n",
    "training_sequences = []          # Empty list to collect each sequence \n",
    "next_chars = []                  # Empty list to collect next character in sequence\n",
    "seq_len, stride = 35, 1          # Define lenth of each input sequence & stride to move before sampling next sequence\n",
    "\n",
    "\n",
    "for i in range(0, len(text) - seq_len, stride):     # Loop over text with window of 35 characters, moving 1 stride at a time\n",
    "    training_sequences.append(text[i: i + seq_len]) # Append sequences to traning_sequences\n",
    "    next_chars.append(text[i + seq_len])            # Append following character in sequence to next_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 166730\n",
      "First sequences: ['[ the tragedie of hamlet by william']\n",
      "Next characters in sequence: [' ']\n",
      "Second sequences: [' the tragedie of hamlet by william ']\n",
      "Next characters in sequence: ['s']\n"
     ]
    }
   ],
   "source": [
    "# Print out sequences and labels to verify\n",
    "\n",
    "print('Number of sequences:', len(training_sequences))\n",
    "print('First sequences:', training_sequences[:1])\n",
    "print('Next characters in sequence:', next_chars[:1])\n",
    "print('Second sequences:', training_sequences[1:2])\n",
    "print('Next characters in sequence:', next_chars[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 43\n"
     ]
    }
   ],
   "source": [
    "# Get sorted list of unique characters in hamlet\n",
    "\n",
    "characters = sorted(list(set(text)))\n",
    "print('Total characters:', len(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '!': 1, '&': 2, \"'\": 3, '(': 4, ')': 5, ',': 6, '-': 7, '.': 8, '1': 9, '5': 10, '9': 11, ':': 12, ';': 13, '?': 14, '[': 15, ']': 16, 'a': 17, 'b': 18, 'c': 19, 'd': 20, 'e': 21, 'f': 22, 'g': 23, 'h': 24, 'i': 25, 'j': 26, 'k': 27, 'l': 28, 'm': 29, 'n': 30, 'o': 31, 'p': 32, 'q': 33, 'r': 34, 's': 35, 't': 36, 'u': 37, 'v': 38, 'w': 39, 'x': 40, 'y': 41, 'z': 42}\n"
     ]
    }
   ],
   "source": [
    "# Make lookup dictionaries to map each unique charatcer with an integers\n",
    "\n",
    "char_indices = dict((l, i) for i, l in enumerate(characters))\n",
    "indices_char = dict((i, l) for i, l in enumerate(characters))\n",
    "\n",
    "print(char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Matrix of zeros\n",
    "# With dimensions : (training sequences, length of each sequence, total unique characters)\n",
    "\n",
    "x = np.zeros((len(training_sequences), seq_len, len(characters)), dtype=np.bool)\n",
    "y = np.zeros((len(training_sequences), len(characters)), dtype=np.bool)\n",
    "\n",
    "\n",
    "for index, sequence in enumerate(training_sequences):     #Iterate over training sequences\n",
    "    \n",
    "    for sub_index, chars in enumerate(sequence):          #Iterate over characters per sequence\n",
    "        \n",
    "        x[index, sub_index, char_indices[chars]] = 1      #Update character position in feature matrix to 1\n",
    "        \n",
    "    y[index, char_indices[next_chars[index]]] = 1         #Update character position in label matrix to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data vectorization completed.\n",
      "Feature vectors shape (166730, 35, 43)\n",
      "Label vectors shape (166730, 43)\n"
     ]
    }
   ],
   "source": [
    "print('Data vectorization completed.')\n",
    "print('Feature vectors shape', x.shape)\n",
    "print('Label vectors shape', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Fun part: Construct a bunch of functions returning different kinds of RNNs, from simple to more complex'''\n",
    "\n",
    "# Simple 1-layered RNN with 128 neurons\n",
    "\n",
    "def SimpleRNN_model():\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(128, input_shape=(seq_len, len(characters))))\n",
    "    model.add(Dense(len(characters), activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two stacked RNN layers, both with 128 neurons\n",
    "\n",
    "def SimpleRNN_stacked_model():\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(128, input_shape=(seq_len, len(characters)), return_sequences=True))\n",
    "    model.add(SimpleRNN(128))\n",
    "    model.add(Dense(len(characters), activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two stacked GRU layers with 128 neurons each\n",
    "\n",
    "def GRU_stacked_model():\n",
    "    model = Sequential()\n",
    "    model.add(GRU(128, input_shape=(seq_len, len(characters)), return_sequences=True))\n",
    "    model.add(GRU(128))\n",
    "    model.add(Dense(len(characters), activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two stacked bi-directional layers with 128 neurons each\n",
    "\n",
    "def Bi_directional_GRU():\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(GRU(128, return_sequences=True), input_shape=(seq_len, len(characters))))\n",
    "    model.add(Bidirectional(GRU(128)))\n",
    "    model.add(Dense(len(characters), activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large GRU model with 3 GRU layers and one densely connected hidden layer, using double dropout strategy\n",
    "\n",
    "def larger_GRU():\n",
    "    model = Sequential()\n",
    "    model.add(GRU(128, input_shape=(seq_len, len(characters)),\n",
    "                       dropout=0.2,\n",
    "                       recurrent_dropout=0.2,\n",
    "                       return_sequences=True))\n",
    "    \n",
    "    model.add(GRU(128, dropout=0.2,\n",
    "                  recurrent_dropout=0.2,\n",
    "                  return_sequences=True))\n",
    "    \n",
    "    model.add(GRU(128, dropout=0.2,\n",
    "                  recurrent_dropout=0.2))\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(len(characters), activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All defined models\n",
    "\n",
    "all_models = [SimpleRNN_model,\n",
    "              SimpleRNN_stacked_model,\n",
    "              GRU_stacked_model,\n",
    "              Bi_directional_GRU, \n",
    "              Bi_directional_GRU,\n",
    "              larger_GRU]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling a character index from a probability array\n",
    "    \n",
    "    \n",
    "def sample(softmax_predictions, sample_threshold=1.0):\n",
    "    \n",
    "    softmax_preds = np.asarray(softmax_predictions).astype('float64')    # Make array of predictions, convert to float\n",
    "    \n",
    "    log_preds = np.log(softmax_preds) / sample_threshold                 # Log normalize and divide by threshold\n",
    "    \n",
    "    exp_preds = np.exp(log_preds)                                        # Compute exponents of log normalized terms\n",
    "     \n",
    "    norm_preds = exp_preds / np.sum(exp_preds)                           # Normalize predictions\n",
    "    \n",
    "    prob = np.random.multinomial(1, norm_preds, 1)                       # Draw sample from multinomial distribution\n",
    "    \n",
    "    return np.argmax(prob)                                               #Return max value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function executed epoch end, generates Prints \n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    global model, model_name\n",
    "    \n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - seq_len - 1)    # Random index position to start sample input sequence\n",
    "    end_index = start_index + seq_len                           # End of sequence, corresponding to training sequence length\n",
    "    \n",
    "    sampling_range = [0.3, 0.5, 0.7, 1.0, 1.2]                  # Sampling entropy threshold\n",
    "    \n",
    "    for threshold in sampling_range:\n",
    "        print('----- *Sampling Threshold* :', threshold)\n",
    "        \n",
    "        generated = ''                                          # Empty string to collect sequence\n",
    "        \n",
    "        sentence = text[start_index: end_index]                 # Random input sequence taken from Hamlet\n",
    "        generated += sentence                                   # Add input sentence to generated\n",
    "        \n",
    "        print('Input sequence to generate from : \"' + sentence + '\"')\n",
    "        \n",
    "        sys.stdout.write(generated)                            # Print out buffer instead of waiting till the end\n",
    "        \n",
    "        \n",
    "        for i in range(400):                                   # Generate 400 next characters in the sequence\n",
    "            \n",
    "            x_pred = np.zeros((1, seq_len, len(characters)))   # Matrix of zeros for input sentence\n",
    "            \n",
    "            for n, char in enumerate(sentence):                # For character in snetence\n",
    "                \n",
    "                x_pred[0, n, char_indices[char]] = 1.          # Change index position for character to 1.\n",
    "                \n",
    "            preds = model.predict(x_pred, verbose=0)[0]        # Make prediction on input vector\n",
    "            \n",
    "            next_index = sample(preds, threshold)              # Get index position of next character using sample function\n",
    "            \n",
    "            next_char = indices_char[next_index]               # Get next character using index\n",
    "            \n",
    "            generated += next_char                             # Add generated character to sequence\n",
    "            sentence = sentence[1:] + next_char\n",
    "            \n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(list, epochs=10):\n",
    "    global model, model_name\n",
    "    \n",
    "    for network in list:   \n",
    "        print('Initiating compilation...')\n",
    "        \n",
    "        # Initialize model\n",
    "        model = network()\n",
    "        # Get model name\n",
    "        model_name = re.split(' ', str(network))[1]  \n",
    "        \n",
    "        #Filepath to save model with name, epoch and loss \n",
    "        filepath = \"C:/Users/npurk/Desktop/Ch5RNN/all_models/versions/%s_epoch-{epoch:02d}-loss-{loss:.4f}.h5\"%model_name\n",
    "        \n",
    "        #Checkpoint callback object \n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "        print('Compiled:', str(model_name))\n",
    "        \n",
    "        # Initiate training\n",
    "        network = model.fit(x, y,\n",
    "              batch_size=100,\n",
    "              epochs=epochs,\n",
    "              callbacks=[print_callback, checkpoint])\n",
    "        \n",
    "        # Print model configuration\n",
    "        model.summary()\n",
    "           \n",
    "        #Save model history object for later analysis\n",
    "        with open('C:/Users/npurk/Desktop/Ch5RNN/all_models/history/%s.pkl'%model_name, 'wb') as file_pi:\n",
    "            pickle.dump(network.history, file_pi)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating compilation...\n",
      "Compiled: SimpleRNN_model\n",
      "Epoch 1/5\n",
      "166730/166730 [==============================] - 32s 192us/step - loss: 2.2292\n",
      "----- Generating text after Epoch: 0\n",
      "----- *Sampling Threshold* : 0.3\n",
      "Input sequence to generate from : \"iudge ' twixt you and me ; if by di\"\n",
      "iudge ' twixt you and me ; if by dist , the be thes , the there , my lord , the thenger . lo the the pore , that wher mast the sing . the seathe , the thes so the come the the comest of that in thet in whel the mather , the thee thet the blath . the theas . be thes thes me the the fore the ke ther weath ald this beather , the brestere , the thou houe mare the wir ther , the there , tho . hou . and the seree the gother . hour somest----- *Sampling Threshold* : 0.5\n",
      "Input sequence to generate from : \"iudge ' twixt you and me ; if by di\"\n",
      "iudge ' twixt you and me ; if by dit , the aramerill which . whor hardese , the mertetis bo the come mand , bed io mo the merowey , wougste somy , and be fore the comy that whele thes the ke thet ere . thouer . and the de beree , and this , at in mere hime thee : ther , then the thes in thes core the preene . ros . in thes gomles in the werle , of he mellere , whe fere thos wing . co ham . the the thom hom . mo thit whell moule sir----- *Sampling Threshold* : 0.7\n",
      "Input sequence to generate from : \"iudge ' twixt you and me ; if by di\"\n",
      "iudge ' twixt you and me ; if by dingerthes tother , goone . ou for and thom ke forthe . whold , maglore haul thou douers , thes marlond , the ald bemer thay . now is for , and the my lore you lowering . mpst thon hamlet in sores mond : lat my cornouger , ho him . more , the couce ve fothing . no hanke goady , whithact thene , the forean yol are the knof . seof thee ig onon s afressenine : youre ; for menthes : at doming . pot hemi----- *Sampling Threshold* : 1.0\n",
      "Input sequence to generate from : \"iudge ' twixt you and me ; if by di\"\n",
      "iudge ' twixt you and me ; if by dikk , oo toucr . whit co do lesrger . io : foed sremy uoce sthewero me , nf they faue farerins gfare ' ren sorxeudeed shourstidich you hecufp , nom thyour . nt a tesrirt ant : ford , buughes ,uel the deate coseedee , ont mueld ifore : fo ke ofoes mox , come bot ir the dowstmy s ond lute sopor . mpyoursterrsall , mander at yous qh , and ; thitg ingouth . bue doranlect , wedleeon radpelor cameat ofre----- *Sampling Threshold* : 1.2\n",
      "Input sequence to generate from : \"iudge ' twixt you and me ; if by di\"\n",
      "iudge ' twixt you and me ; if by dinithagnis ; az ' blublithde , to hellere uondarcadiestod gaturss ond youiseadofy , in youigkll tord th lluewseake tas auro myis but been . thtil , seafer abut sfobithi. is laskengenout gobettussoes nre mockgoum steea , lost ?our weobexe , my thar . gomt of pros 'ed , ali bla them , brastrof are preesed vfolr why . dof arserker) . fuld rok at ' d bedstofs nosent be -rerur ; thos hiskengeake thime oEpoch 2/5\n",
      "166730/166730 [==============================] - 29s 176us/step - loss: 1.9585\n",
      "----- Generating text after Epoch: 1\n",
      "----- *Sampling Threshold* : 0.3\n",
      "Input sequence to generate from : \"t neerer the offence : to beare all\"\n",
      "t neerer the offence : to beare all the wist of this then the welle , and deere , and the will the congen , and in the wead , and will the weat my loud , and the reale , and the seat , what me the whele , the peay , and mas thes , the weere , the the wing the will the will . the heare , that you ham . do , and the seale , and word , the will ste be the lead , the pray and , the thes cond , why she king . what the peryou , and and t----- *Sampling Threshold* : 0.5\n",
      "Input sequence to generate from : \"t neerer the offence : to beare all\"\n",
      "t neerer the offence : to beare all , them ghe the wee the peide , the will with and we the ward , the far nones , the sore , the whel and see now the kend , what st in arde , the seace stall the llaken . the sance , and seo , and the poredanke sence will ving of the the wind thes , and here , and will sio , and but you mad , and not the baster , i ham . the gored , and whil ' t a pely your thas of hee . whith me that is not thet t----- *Sampling Threshold* : 0.7\n",
      "Input sequence to generate from : \"t neerer the offence : to beare all\"\n",
      "t neerer the offence : to beare all kis lerole my lice co kes in leke , heakes desen ' d ande frothe olit thas opres ' s . phaes , the rede ' tare ald mandes . hop . the way to ham . and heaue for . e his hish the mis mane , we laser sanfe to gone , thy these the lord , munt to be by the sanene . e sen enth nour . ko woud litgat , andidn ard . my leaden then the myere shade betst in whe asestreneste ' s soweld , and dorle . this no----- *Sampling Threshold* : 1.0\n",
      "Input sequence to generate from : \"t neerer the offence : to beare all\"\n",
      "t neerer the offence : to beare all . the whexerseuemme arr thae rey shat sis ancalsh comakeiki aseen to fethen in thag vn lyed of ha rephet ir we wand are kente kfale thaid fallgh . foopst ingtken . wey : at eele wod ditkikis daspleses rewae ts now lneers . ande lere ham st bessan , thee an wiret mistere fy wurks of hum vicr . and : hes lible tiss and rikener , ame thes discrtonabe stryenke a misen , y theme wity lay sikengs bue b----- *Sampling Threshold* : 1.2\n",
      "Input sequence to generate from : \"t neerer the offence : to beare all\"\n",
      "t neerer the offence : to beare allem , th; vpram , ' d bo moreat non ntrolefe kis dold my besioer shat , theso the queckesr . vf lury , be apl bewielatoinstersae . i merse kefade hakexo . e duantisod bbhecr . thaz ' sehesst , asthgect , youe a ay dam caldues welleniug tol trte beas weditiue tfraene . on the fron. thinke . thal qh . ' ot your mye . bpencuekd sse , meangs visenstoke sofattys thea dos( mast on tulentsin tisele tore ,Epoch 3/5\n",
      " 88200/166730 [==============>...............] - ETA: 14s - loss: 1.8744"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-a98d37336cbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_models\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-d8dc03fd62cd>\u001b[0m in \u001b[0;36mtest_models\u001b[1;34m(list, epochs)\u001b[0m\n\u001b[0;32m     24\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m               callbacks=[print_callback, checkpoint])\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# Print model configuration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1400\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_models(all_models, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1a051d7a208>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
