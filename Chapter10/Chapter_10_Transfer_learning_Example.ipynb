{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.datasets import cifar10\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 32, 32\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "num_classes = 10\n",
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers[:5]:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(10, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 21,609,546\n",
      "Trainable params: 21,496,970\n",
      "Non-trainable params: 112,576\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 2.0521 - acc: 0.2456 - val_loss: 1.4976 - val_acc: 0.4639\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 1.3411 - acc: 0.5246 - val_loss: 1.0518 - val_acc: 0.6275\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 1.0865 - acc: 0.6199 - val_loss: 0.9572 - val_acc: 0.6651\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.9666 - acc: 0.6647 - val_loss: 0.8485 - val_acc: 0.7020\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.8881 - acc: 0.6946 - val_loss: 0.8231 - val_acc: 0.7164\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.8253 - acc: 0.7127 - val_loss: 0.7643 - val_acc: 0.7350\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.7822 - acc: 0.7309 - val_loss: 0.7565 - val_acc: 0.7379\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.7509 - acc: 0.7419 - val_loss: 0.7356 - val_acc: 0.7415\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.7145 - acc: 0.7530 - val_loss: 0.7193 - val_acc: 0.7530\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.6848 - acc: 0.7642 - val_loss: 0.6956 - val_acc: 0.7609\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.6612 - acc: 0.7730 - val_loss: 0.6728 - val_acc: 0.7652\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.6422 - acc: 0.7791 - val_loss: 0.6724 - val_acc: 0.7678\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.6176 - acc: 0.7870 - val_loss: 0.6548 - val_acc: 0.7748\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.6026 - acc: 0.7923 - val_loss: 0.6246 - val_acc: 0.7848\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.5788 - acc: 0.8004 - val_loss: 0.6380 - val_acc: 0.7820\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.5666 - acc: 0.8051 - val_loss: 0.6193 - val_acc: 0.7846\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.5484 - acc: 0.8112 - val_loss: 0.6321 - val_acc: 0.7851\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.5401 - acc: 0.8133 - val_loss: 0.6044 - val_acc: 0.7942\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.5207 - acc: 0.8203 - val_loss: 0.6112 - val_acc: 0.7912\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.5040 - acc: 0.8272 - val_loss: 0.6218 - val_acc: 0.7928\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.4904 - acc: 0.8324 - val_loss: 0.5804 - val_acc: 0.8036\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.4835 - acc: 0.8341 - val_loss: 0.6582 - val_acc: 0.7834\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.4669 - acc: 0.8382 - val_loss: 0.5779 - val_acc: 0.8018\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.4509 - acc: 0.8451 - val_loss: 0.5853 - val_acc: 0.8049\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.4412 - acc: 0.8491 - val_loss: 0.5613 - val_acc: 0.8100\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.4288 - acc: 0.8522 - val_loss: 0.5920 - val_acc: 0.8051\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.4220 - acc: 0.8554 - val_loss: 0.5801 - val_acc: 0.8046\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.4081 - acc: 0.8588 - val_loss: 0.5568 - val_acc: 0.8122\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.3967 - acc: 0.8628 - val_loss: 0.5615 - val_acc: 0.8149\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.3881 - acc: 0.8682 - val_loss: 0.5683 - val_acc: 0.8140\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.3776 - acc: 0.8686 - val_loss: 0.5923 - val_acc: 0.8063\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.3672 - acc: 0.8726 - val_loss: 0.5693 - val_acc: 0.8118\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 267s 5ms/step - loss: 0.3565 - acc: 0.8776 - val_loss: 0.5699 - val_acc: 0.8158\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 762s 15ms/step - loss: 0.3445 - acc: 0.8819 - val_loss: 0.5747 - val_acc: 0.8169\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 765s 15ms/step - loss: 0.3345 - acc: 0.8857 - val_loss: 0.5849 - val_acc: 0.8138\n",
      "Epoch 36/50\n",
      "43264/50000 [========================>.....] - ETA: 1:36 - loss: 0.3339 - acc: 0.8864"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "model_final.fit(x_train,y_train,\n",
    "batch_size=batch_size,\n",
    "epochs = epochs,\n",
    "validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
