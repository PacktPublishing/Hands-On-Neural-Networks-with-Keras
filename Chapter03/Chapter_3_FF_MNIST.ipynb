{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached https://files.pythonhosted.org/packages/ed/29/d97b6252591da5f8add0d25eecda296ea72729a0aad7998edba1981b47c8/numpy-1.16.2-cp36-cp36m-win_amd64.whl\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.16.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  The script f2py.exe is installed in 'C:\\Users\\npurk\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "You are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#! pip install --upgrade numpy --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version : 1.16.2\n",
      "Keras version 2.2.4\n",
      "With tensorflow backend, version :  1.13.1\n"
     ]
    }
   ],
   "source": [
    "# Version check\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print('NumPy version :' , np.__version__)\n",
    "print('Keras version' , keras.__version__)\n",
    "print('With tensorflow backend, version : ', tf.__version__ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check type and dimensions\n",
    "\n",
    "type(x_train[0]), x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x240398f7ba8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot out an example\n",
    "\n",
    "plt.imshow(x_train[0], cmap = plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "\n",
    "x_train = keras.utils.normalize(x_train, axis=1)  # scaling the pixel values that are between 0-225\n",
    "x_test = keras.utils.normalize(x_test, axis=1)    \n",
    "                                                  #experiment without normalization, makes difference in learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2403445b3c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot normalized\n",
    "\n",
    "plt.imshow(x_train[0], cmap = plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\npurk\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Build a model : feed forward net\n",
    "\n",
    "model = Sequential() \n",
    "\n",
    "model.add(Flatten(input_shape=(28, 28,)))\n",
    "model.add(Dense(1024, kernel_regularizer=regularizers.l2(0.0001), activation='relu'))      #, kernel_initializer='glorot_uniform', bias_initializer='zeros'))\n",
    "model.add(Dense(28, kernel_regularizer=regularizers.l2(0.0001), activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compile model\n",
    "\n",
    "model.compile(optimizer='adam',#'sgd'\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 28)                28700     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                290       \n",
      "=================================================================\n",
      "Total params: 832,830\n",
      "Trainable params: 832,830\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# View model config\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\npurk\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.3579 - acc: 0.9184\n",
      "Epoch 2/5\n",
      "19500/60000 [========>.....................] - ETA: 6s - loss: 0.1950 - acc: 0.9622"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-abb9b68e1c29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Initiate training session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# other arguments validation split=0.33, batch size=10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initiate training session\n",
    "\n",
    "model.fit(x_train , y_train, epochs=5, batch_size=100) # other arguments validation split=0.33, batch size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 98us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1425468367099762, 0.9759]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model \n",
    "\n",
    "model.save('mnist_nn.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "\n",
    "load_model = keras.models.load_model('mnist_nn.model')  #nesting & function argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the inference graph generated by the model to predict class labels on our test set\n",
    "\n",
    "predictions = load_model.predict([x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network thinks it is seeing the number : | 2 |\n"
     ]
    }
   ],
   "source": [
    "# Choose individuaL sample from test set \n",
    "sample_index = 1\n",
    "\n",
    "#print maximum predicticted value sample\n",
    "print('Network thinks it is seeing the number : |', np.argmax(predictions[sample_index]), '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24b02c60b00>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the actual sample to verify\n",
    "\n",
    "plt.imshow(x_test[sample_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
